#+TITLE: Partitioned Table Functions in Hive
#+AUTHOR: Harish Butani
#+EMAIL:  harish.butani@sap.com

* Concepts
** Partition Specification
- specify how an input dataset is to be partitioned and how partitions
  should be ordered.
- Can be specified in multiple ways:
  - With distribute by, sort by clause combination.
  - With a cluster by clause
  - *Note:* For Table Functions and Windowing clauses a Query with just a
    distribute by clause is treated as a Partition Specification
    where the Input rows are partitioned by the columns in the
    distribute by clause and rows in a Partition are sorted on the
    partition columns. So the cluster by clause is redundant.
  - With a window specification. See below
** Window specification
- Each row in a Partition can be operated on in the context of a
  Window of surrounding rows.
- A window can be specified as a Range of Rows, or as a Range of Values.
- /The window clause can specify everything: the distribute by, sort
  by and the window frame./
- See Grammar details on how to specify a Window.
- A Window maybe specified for each UDAF invocation, or globally for
  the Query and then referenced by a UDAF invocation.
** Partitioned Table Function
- A Function whose contract is to operate on an Input Dataset and
  return an Output Dataset. /So interface is Table In, Table Out./
- A PTF also operates on the Input in Partitions; the Partitions are
  ordered.
- A PTF invocation must specify the Input Dataset and how to
  partition and order the Input. The partitioning may not be specified
  explicitly, as PTFs can be chained; so a PTF can inherit the
  partition specification from a PTF up the function chain.
- A PTF may also operate on the /raw input/ before it is partitioned. 
- Operating on data implies:
  - it can be reshaped ( the schema can be altered)
  - the contract is always (both on raw data and on partitioned data)
    Table in/Table out.

* Grammar changes

** for partition table functions

#+begin_src sql
fromSource :
   (tableSource | subQuerySource | tableFunction ) (lateralView^)*
    ;

tableFunction :
   Identifier LPAREN
     (
        (
        selectStatement |
        tableFunction (clusterByClause | distributeByClause (sortByClause)? )? 
        )
        (COMMA expression)*
     )
#+end_src

- In Hive grammar we extend the from Clause to have a new form, a
  partition table Function invocation.
- The table Function invocation has the following form:
  - The function Name
  - The input to the table function, which can be:
    - any select statement, this must contain a Partition
      Specification ( with a Distribute, Cluster or Windowing clauses)
    - another Table function invocation. If the input is a table
      function invocation then it can be succeeded by a Distribute By
      or Cluster By specification.
- See *Windowing2.g* tableSpec Non-Terminal.
  - Now we can allow a selectStatement to be the input of a PTF not
    just a hiveTable. No need to use ugly syntax to enable a SQL subquery.

** for windowing clauses
#+begin_src sql
function :
    functionName
    LPAREN
      (
        (star=STAR)
        | (dist=KW_DISTINCT)? (expression (COMMA expression)*)?
      )
    RPAREN 
    ({isWindowFunction(functionName.getText()}?
     OVER window_specification
    )?
;
window_specification :
  Identifier? (clusterByClause | distributeByClause sortByClause?)? window_frame?
;
window_frame :
 window_range_expression |
 window_value_expression
;

selectStatement
   :
   selectClause
   fromClause
   whereClause?
   groupByClause?
   havingClause?
   orderByClause?
   clusterByClause?
   distributeByClause?
   sortByClause?
   limitClause?
   windowClause?
;

/* body, regular_body also get the windowClause */

window_clause :
  WINDOW window_defn (COMMA window_defn)*
;  

window_defn :
  Identifier AS window_specification
;
#+end_src sql

- See Windowing2.g for full details of window frame and other Non-Terminals.
- We propose that a Hive function expression can have a window specification if it is a
  Windowing Function.
- All UDAFs are Windowing Functions; plus Ranking functions (these
  are implemented as UDAFs, but are not available in Group By queries).
- Syntactically it is possible to have a windowing expression in the
  where clause or having clause. But obviously we throw an error on this.
  - another option is to have a special form, see /Window_Function/ Non
    Terminal in Windowing2.g.
    - But the issue with this is, then the grammar requires semantic
      lookahead to distinguish a Window_Function and a regular UDAF
      call. Hive.g doesn't use this, in fact has a fixed lookahead of 3.
- We extend a Hive Query to contain 1 or more /window definitions/; these can be
  referred to in the window_specifications of functions.

* Semantics of the new forms
** Informally
*** A Query on a Partition Table Function
- remove the Partition Specification from the inner most
  SelectStatement in the Function Chain.
- Generate a plan for this  altered SelectStatement; let's call it the *InOperator*
- break Function Chain into subchains; break at each Function that
  has a Partition Specification for its input.
- for each subchain generate:
  - InOp -> ReduceSink -> Extract -> PTFOp
- For the first subchain the input is the InOperator; for subsequent
  chains the output of the previous subchain is the input.
- If the first function in a subchain has Map-Side processing, then the Op chain
  will be:
 - Input -> PTFOp(map-side) -> ReduceSink -> Extract -> PTFOp

*** A Query with Windowing clauses
- Generate the Operator graph with the Windowing Functions and Partition
  Specification removed from the Select Clause.
- Handle the Windowing clauses as an invocation on the internal
  Table Function WindowingTableFunction. Its input is the Operator
  generated for the rest of the Query.
- As a special case if the Query has Windowing Functions and the
  fromSource is just a PTF chain invocation then add the special
  WindowingTableFunc to the end of the chain.

** Examples
Will explain the details through a series of examples.
*** Basic Windowing
Consider the following Distribute By query on the TPCH part table:
#+begin_src sql
select p_mfgr, p_name, p_size
from part
distribute by p_mfgr
sort by p_name;
#+end_src sql
the *Plan* for this Query is:
#+begin_src sql
TblScan -> Select -> Reduce Output -> Extract -> File Out
#+end_src sql
Now consider the Query expanded to do Ranking and Sum over a window:
#+begin_src sql
select p_mfgr, p_name, p_size,
rank() as r,
denserank() as dr,
sum(p_retailprice) over rows between unbounded preceding and current row as s1
from part
distribute by p_mfgr
sort by p_name;
#+end_src sql

This is *translated* using the following rules:
- Convert this into an invocation on the special internal PTF
  WindowingTableFunc.
  - Its arguments come in pairs: expression, alias.
- push everything but the Windowing Clauses and Partition Spec as
  Input of the WindowingTableFunc invocation.

So the above query is syntactic sugar for:
#+begin_src sql
select p_mfgr, p_name, p_size, r, dr
from windowingTableFunc(select p_mfgr, p_name, p_size from part 
                        distribute by p_mfgr
                        sort by p_name,
                        rank(), 'r'
                        denserank(), 'dr'
                        )
;
#+end_src sql

the *Plan* for this Query is:
#+begin_src sql
TblScan -> Select -> Reduce Output -> Extract -> PTF -> File Out
#+end_src sql

- The inner SelectStatement generates the TableScan -> Select
- While the handling of the Partitioned Table Function chain generates the rest
  of the Plan.
- In this case the PTF Operator has the single WindowingTabFunc in its
  Function Chain. See ?? for details on PTFOperator.

*Things to note:*
- you can now specify aggregations when there is a Partition Specification.
- This is handled after GroupBy processing.
- See below for handling of a Query with GroupBy and Windowing.

*Alternative forms:*
The Partition Specification can be specified in other ways.

The Rule of how a Partition Specification is associated with an Input is:
- The Query must have a Partition specification specified, either
  through a Distribute/Cluster/Sort clauses, Query window clauses or
  Function window specifications.
- If multiple Partition specifications are specified, they must all
  match. (Will allow multiple ordering in the future.)
- Functions that don't have a Partition Spec specified will use the
  Partition Spec associated with the Query.

So the above Query can also be specified as:

/Window Specification:/
#+begin_src sql
select p_mfgr, p_name, p_size,
rank() as r,
denserank() as dr,
sum(p_retailprice) over w1
from part
window w1 as distribute by p_mfgr 
             sort by p_name 
             rows between unbounded preceding and current row as s1
;
#+end_src sql

  - Partition Specification comes from the Window clause.
  - The sum function directly refers to the Window clause, w1.
  - This implies that the Query is applied on the Partition
    Specification in w1.
  - Rank and DenseRank apply on the Partition Specification
    associated with the Query.

/Window Specification and Distribute\/Sort:/
#+begin_src sql
select p_mfgr, p_name, p_size,
rank() as r,
denserank() as dr,
sum(p_retailprice) over w1
from part
distribute by p_mfgr
sort by p_name
window w1 as rows between unbounded preceding and current row as s1
;
#+end_src sql


*** Windowing + Join
Consider the Query:
#+begin_src sql
select p_mfgr, p_name, p_size,
sum(l_extendedprice),
sum(l_quantity)
from part join lineitem on 
   (part.p_partkey = lineitem.l_partkey)
distribute by p_mfgr 
sort by p_name;
#+end_src sql

Same rule applies:
- push everything but the Windowing Clauses and Partition Spec as
  Input of the WindowingTableFunc invocation.

So this is syntactic sugar for:
#+begin_src sql
select p_mfgr, p_name, p_size, _col0, _col1
from windowingTableFunc((select p_mfgr, p_name, p_size,
                                l_extendedprice, l_quantity
                         from part join lineitem on 
                             (part.p_partkey =
                             lineitem.l_partkey)  
                         )
                        distribute by p_mfgr
                        sort by p_name,
                        sum(l_extendedprice), '_col0'
                        sum(l_quantity), '_col1'
                        )
;
#+end_src sql


The *Plan* for this Query is:
#+begin_src sql
Job1: TScan(part), TScan(litem) -> Join -> Select -> File Out
Job2: Read Previous Out -> Reduce Out -> Extract -> PTF -> File Out
#+end_src sql

*** Windowing + Group By
Consider the Query:
#+begin_src sql
select p_mfgr, p_name, avg(p_size) as avgSz,
rank() as r,
denserank() as dr,
sum(p_retailprice) over rows between unbounded preceding and current row as s1
from part
group by p_mfgr, p_name
distribute by p_mfgr
sort by p_name;
#+end_src sql

Again same general rules applies. This is handled as:

#+begin_src sql
select p_mfgr, p_name, p_size, r, dr, s1
from windowingTableFunc((select p_mfgr, p_name, avg(p_size) as avgSz
                         from part 
                         group by p_mfgr, p_name
                         )
                        distribute by p_mfgr
                        sort by p_name,
                        rank(), 'r',
                        denserank(), 'dr',
                        sum(p_retailprice) over rows between unbounded
                                       preceding and current row, 's1'
                       )
;
#+end_src sql
/How do we decide which aggregations to push to the Group by?/
- push any non ranking, and windowing based aggregations to group by
- also any aggregation that refer to lead/lag will not be pushed.

*** Windowing + Having
Suppose we want rank parts within each Mfgr and only return the top 3
within each partition. /We propose to use the having clause to
specify this/. So consider the Query:
#+begin_src sql
select p_mfgr, p_name, 
rank() as r,
denserank() as dr,
sum(p_retailprice) over rows between unbounded preceding and current row as s1
from part
where p_size > 50
distribute by p_mfgr
sort by p_name
having r < 3;
#+end_src sql

Here:
- the having clause is applied on each output partition.
- Can refer to columns in the output, i.e. after windowing has been
  performed.

What if there is a GroupBy and windowing; then Having is associated
with Group By.
So the following e.g. will give an error to the effect: ' Unknown
column r'; because the Group By query will not know about the ranking
column 'r'.

#+begin_src sql
select p_mfgr, p_name, 
rank() as r,
denserank() as dr,
sum(p_retailprice) over rows between unbounded preceding and current row as s1
from part
group by p_mfgr, p_name
where p_size > 50
distribute by p_mfgr
sort by p_name
having r < 3;
#+end_src sql

*** Basic Table Function
Assume:
- there is a Table Function *Noop* in the Table Function library;
  this function takes no arguments. It returns the Partition given
  to it as is.
- Also there is a *NoopMap* Table Function. This is similar to Noop,
  except that it also operates on the raw data(before it is partitioned). Like the
  Noop function it doesn't change the input Partition in any way.

The simplest PTF Query is:
#+begin_src sql
select p_mfgr, p_name, p_size
from noop(part 
          distribute by p_mfgr
          sort by p_name
          )
;
#+end_src sql

In terms of the Script Operator this sort of means:
#+begin_src sql
from
(
select transform(p_mfgr, p_name, p_size...)
using '/bin/cat'
  as (p_mfgr, p_name, p_size,...)
from part
distribute by p_mfgr
sort by p_name
) map_side
select transform(p_mfgr, p_name, p_size,...)
using 'java .. NoopFunction...'
as (p_mfgr, p_name, p_size,...)
#+end_src sql
Apart from syntactically being much easier, the PTF mechanism has
several other advantages. (add reference to SQW docs folder here)


The *Plan* for this Query is like a Query with Distribute By/Cluster
But with the addition of the PTF Operator:
#+begin_src sql
TblScan -> Select -> Reduce Output -> Extract -> PTF -> File Out
#+end_src sql

If in place of /Noop/ we invoke /NoopMap/ PTF then the plan changes
so:
#+begin_src sql
TblScan -> Select -> PTF -> Reduce Output -> Extract -> PTF -> File Out
#+end_src sql
The PTF has the option of reshaping the raw data before it is
distributed.

Things to note:
- the input of a PTF can be a /selectStatement/.
- the PTF form of the Query can appear as a SubQuery or a JoinSource.
- So a PTF invocation can be part of a complex data flow.

*** A PTF chain
The input to a PTF can be another PTF invocation.
Consider the Query:
#+begin_src sql
select p_mfgr, p_name, p_size
from noop(noop(part
               distribute by p_mfgr
               sort by p_size
          ) 
          distribute by p_mfgr
          sort by p_name
          )
;
#+end_src sql

In script operator terms this Query is trying to do the following:
#+begin_src sql
from
(
select transform(p_mfgr, p_name, p_size...)
using '/bin/cat'
  as (p_mfgr, p_name, p_size,...)
from (
   from
   (
   select transform(p_mfgr, p_name, p_size...)
   using '/bin/cat'
     as (p_mfgr, p_name, p_size,...)
   from part
   distribute by p_mfgr
   sort by p_size
   ) map_side
   select transform(p_mfgr, p_name, p_size,...)
   using 'java .. NoopFunction...'
   as (p_mfgr, p_name, p_size,...)
) map_side_outer
distribute by p_mfgr
sort by p_name
) map_side_outer
select transform(p_mfgr, p_name, p_size,...)
   using 'java .. NoopFunction...'
   as (p_mfgr, p_name, p_size,...)
#+end_src sql

The *Plan* for the above query is:
#+begin_src sql
Job1: TScan -> Select -> Transform -> Reduce Out -> Extract -> Select -> Transform -> File Out
Job2: File Read -> Transform -> Reduce Out -> Extract  -> Select -> Transform -> File Out
#+end_src sql


The *Plan* for the PTF query is similar:
#+begin_src sql
Job1: TScan -> Select -> Reduce Out -> Extract -> PTF -> File Out
Job 2: File Read -> Select -> Reduce Out -> Extract -> PTF -> File Out
#+end_src sql

The Rule is:
- to have a Job for each subchain at which a partitioning is required.
- So if the outer query didn't have a distribute by, sort by clause;
  then both PTF invocations would be handled in the first PTF operator.

*** Windowing + Table Function
In the case that there are Windowing Clauses and the fromSource is
only a PTF invocation ( no joins, group bys ) then we add on the
WindowingTableFunc to the end of the chain. But if there is a group
by or join then the Query is handled without the Windowing clauses (
and partitioning specification) and then the Windowing clauses is
handled as the special PTF WindowingTableFunc.

So the following query:
#+begin_src sql
select p_mfgr, p_name, p_size,
rank() as r,
denserank() as dr,
sum(p_retailprice) over rows between unbounded preceding and current row as s1
from noop(part 
          distribute by p_mfgr
          sort by p_name
          )
#+end_src sql

Is handled as:

#+begin_src sql
select p_mfgr, p_name, p_size, r, dr, s1
from windowingTableFunc(noop(
                             part
                             distribute by p_mfgr
                             sort by p_name
                             )
                        )
#+end_src sql

But the following query:
#+begin_src sql
select p_mfgr, p_name, p_size,
rank() as r,
denserank() as dr,
sum(p_retailprice) over rows between unbounded preceding and current row as s1
from noop(part 
          distribute by p_mfgr
          sort by p_name
          ) p join lineitem l on (p.p_partkey = l.l_partkey)
#+end_src sql

is handled as:
#+begin_src sql
select p_mfgr, p_name, p_size, r, dr, s1
from windowingTableFunc(select *
                        from noop(
                             part
                             distribute by p_mfgr
                             sort by p_name
                             ) p join lineitem l on (p.p_partkey =
                             l.l_partkey)
                         distribute by p_mfgr
                         sort by p_name
                        )
#+end_src sql

*** Table Function + Join
The Table function is handled as a Sub Query. The output of the Table
function is used to generate the Join Plan.

*** Table Function + Group By
The Table function is handled as a Sub Query. The output of the Table
function is used to generate the Group By Plan.

*** Interaction with other clauses
- Order By not allowed; just like now:
Cannot have both ORDER BY and DISTRIBUTE BY clauses.
- Limit by: applied at the very end.

*** PTF plus Lateral View
TBD
Don't understand the plan for this query. Why are there 2 transform
Script invocations?
#+begin_src sql
On table:
create table part_arr(p_partkey int, p_name string, p_mfgr string, p_tags array<string>);

from
   (
   select transform(p_mfgr, p_name, p_tags)
   using '/bin/cat'
     as (p_mfgr string, p_name string, p_tags array<string>)
   from part_arr 
   distribute by p_mfgr
   sort by p_name
   ) map_side lateral view explode(p_tags) adTable AS adid
   select transform(p_mfgr, p_name)
   using 'java .. NoopFunction...'
   as (p_mfgr, p_name)
#+end_src sql

*** Error: Windowing without Partition Spec
The following Query will be flagged as an error:
#+begin_src sql
select 
rank() as r,
denserank() as dr,
sum(p_retailprice) over rows between unbounded preceding and current row
from part;
#+end_src sql

The Rule is:
- a Windowing clause or a Ranking function must be in the Context of
  a Partitioning specification.

*** Error: Windowing with Script Operator
The following query will be flagged as an error:
#+begin_src sql
select transform(p_partkey, sum(p_size))        
using '/bin/cat' as p_partkey, p_size   
group by p_size;
#+end_src sql

This flagged currently:
Expression not in GROUP BY key 'p_partkey'




* Implementation details
** Changes to genPlan
- If a PTF Chain is a fromSource:
  - the 1st source of the Chain should be added to the QueryBlock as
    a source table or as a SubQuery.
  - Invoke genPTFChain on the AST of the PTFChain. The input is the
    Operator for the Table or the SubQuery.
  - Generate a ReduceSink -> Extract -> PTFOp for each subchain.
  - If the Query has WindowingClauses and no Group By and only a
    PTFChain as the input add the WindowingTableFunc to the chain.
- If there are Windowing clauses:
  - provided they not already handled by appending to the from Clause
    PTF Chain.
  - Setup a PTFChain with only the WindowingTableFunction PTF.
    - Its input is the Operator after handling the Having clause.
